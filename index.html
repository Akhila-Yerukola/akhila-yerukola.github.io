<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Akhila Yerukola</title>

  <meta name="author" content="Akhila Yerukola">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet" type="text/css" href="stylesheet.css">

  <script src="js/scramble.js"></script>
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Akhila Yerukola</name>
              </p>
              <p><i>Hi!</i> I am an AI Research Engineer at <a href="https://www.sra.samsung.com/">Samsung Research America (SRA)</a>. I work at the <a href="https://www.sra.samsung.com/artificial-intelligence/">Artificial Intelligence Center</a>, advised by <a href="https://www.linkedin.com/in/hongxiajin">Hongxia Jin</a>.
              </p>
              <p>
                I graduated from Stanford University with Masters in Computer Science in 2019. I was a part of the <a href="https://nlp.stanford.edu/">Stanford NLP Group</a>, where I was advised by <a href="https://nlp.stanford.edu/manning/">Professor Chris Manning</a>. I received my B.Tech in Computer Science from National Institute of Technology Tiruchirappalli, Tamil Nadu, India in 2016.
              </p>
              <p>
                My current research interests include low resource NLP and language generation in dialog systems.
                <br> <br>
                Here is my <a href="data/Akhila_Resume.pdf">CV</a> [Updated Oct 2020].
              </p>
              <p style="text-align:center">
                Email:
                <font id="email">
                  <noscript><i>Please enable Javascript to view</i></noscript>
                </font>
     <br>
                <script>
                emailScramble = new scrambledString(document.getElementById('email'),
                    'emailScramble', 'ikaeogiluaomklr.halay@cm',
                    [11, 9, 17, 1, 22, 15, 18, 12, 3, 7, 5, 23, 4, 6, 2, 20, 10, 13, 19, 8, 0, 14, 21, 16]);
                </script>

                <a href="https://github.com/Akhila-Yerukola">GitHub</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=rFL468UAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <a href="https://twitter.com/akhila_yerukola">Twitter</a> &nbsp/&nbsp
                <a href="https://www.linkedin.com/in/akhilayerukola/">LinkedIn</a>

              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/akhila_profile.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/akhila_profile.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>


        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Publications</heading>
              <ul>

                        <li>
                        <p>
                            <b><a href="https://arxiv.org/pdf/1909.10705.pdf">Do Massively Pretrained Language Models Make Better Storytellers?</a></b><br>
                            Abigail See, Aneesh Pappu<sup>∗</sup>, Rohun Saxena<sup>∗</sup>, <b><u>Akhila Yerukola</u><sup>∗</sup></b>, Christopher D. Manning<br>
                            <b>* equal contribution </b> <br>
                            Conference on Computational Natural Language Learning (CoNLL), 2019.<br>
                            [<a href="https://github.com/abisee/story-generation-eval">Code</a>][<a href="bibs/see2019massively.bib">bib</a>]
                        </p>
                        </li>


              </ul>

            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Teaching Experience</heading>
				      <ul>
                <li>
                  In Spring 2019, I was a TA for <a href="https://web.stanford.edu/class/cs224u/">CS224U</a> (Natural Language Understanding), taught by <a href="https://web.stanford.edu/~cgpotts/">
                Christopher Potts</a>  and <a href="https://nlp.stanford.edu/~wcmac/">Bill MacCartney</a> . I worked with of 10 CAs for 250+ students, and mentored  10+ student teams for the course project. I also taught a lecture on “Probing black box models.” (<a href="https://www.youtube.com/watch?v=WXLb4h2A724&list=PLoROMvodv4rObpMCir6rNNUlFAn56Js20&index=15">Link</a>)
                </li>
                <li>
                  In Fall 2018, I was a TA for <a href="http://cs229.stanford.edu/">CS229 </a>  (Machine Learning), taught by <a href="https://www.andrewng.org/"> Andrew Ng </a> . I worked with a team of 30+ CAs for 850+ students. I also mentored 30 student teams for the course project.
                </li>

				      </ul>

            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Selected Awards</heading>
				      <ul>
                <li>
                  Second Best Project Award, CS231n (Convolutional Neural Networks for Visual Recognition) 2018. </li>
                <li>
                  Second Best Project Award, CS224n (NLP with Deep Learning) 2018. </li>
                <li>
                  Third Highest GPA Award, Department of Computer Science, NITT, 2015.
                </li>
                <li>
                  Full undergraduate scholarship, Ministry of Human Resource Development (MHRD), India 2012-2016.
                </li>
				      </ul>

            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <p style="text-align:left;font-size:small;">
                This website template is from <a href="https://jonbarron.info/" style="text-align:right;font-size:small;">Jon Barron</a> and <a href="https://jeffdonahue.com/" style="text-align:right;font-size:small;">Jeff Donahue</a>.
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
